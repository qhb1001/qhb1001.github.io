<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Beyond</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://notes-hongbo.top/"/>
  <updated>2018-11-19T15:09:28.191Z</updated>
  <id>http://notes-hongbo.top/</id>
  
  <author>
    <name>秦baibai</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《货币金融学》</title>
    <link href="http://notes-hongbo.top/2018/11/19/%E3%80%8A%E8%B4%A7%E5%B8%81%E9%87%91%E8%9E%8D%E5%AD%A6%E3%80%8B/"/>
    <id>http://notes-hongbo.top/2018/11/19/《货币金融学》/</id>
    <published>2018-11-19T14:41:57.000Z</published>
    <updated>2018-11-19T15:09:28.191Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一章-为什么？"><a href="#第一章-为什么？" class="headerlink" title="第一章 为什么？"></a>第一章 为什么？</h1><h2 id="为什么研究金融市场？"><a href="#为什么研究金融市场？" class="headerlink" title="为什么研究金融市场？"></a>为什么研究金融市场？</h2><p>在金融市场中，资金从那些拥有闲置货币的人手中转移到资金短缺的人手中。债券市场和股票市场等金融市场将资金从没有生产用途的人向右生产用途的人转移，从而提高了经济效率。</p><p>那么它们到底是怎么运转的呢！不好奇吗！</p><h3 id="债券市场与利率"><a href="#债券市场与利率" class="headerlink" title="债券市场与利率"></a>债券市场与利率</h3><h4 id="证券是什么？"><a href="#证券是什么？" class="headerlink" title="证券是什么？"></a>证券是什么？</h4><blockquote><p> <strong>证券</strong>是用来证明<a href="https://wiki.mbalib.com/wiki/%E6%8C%81%E6%9C%89%E4%BA%BA" target="_blank" rel="noopener">持有人</a>享有的某种特定权益的凭证。如<a href="https://wiki.mbalib.com/wiki/%E8%82%A1%E7%A5%A8" target="_blank" rel="noopener">股票</a>、<a href="https://wiki.mbalib.com/wiki/%E5%80%BA%E5%88%B8" target="_blank" rel="noopener">债券</a>、<a href="https://wiki.mbalib.com/wiki/%E6%9C%AC%E7%A5%A8" target="_blank" rel="noopener">本票</a>、<a href="https://wiki.mbalib.com/wiki/%E6%B1%87%E7%A5%A8" target="_blank" rel="noopener">汇票</a>、<a href="https://wiki.mbalib.com/wiki/%E6%94%AF%E7%A5%A8" target="_blank" rel="noopener">支票</a>、<a href="https://wiki.mbalib.com/wiki/%E4%BF%9D%E9%99%A9%E5%8D%95" target="_blank" rel="noopener">保险单</a>、存款单、<a href="https://wiki.mbalib.com/wiki/%E5%80%9F%E6%8D%AE" target="_blank" rel="noopener">借据</a>、<a href="https://wiki.mbalib.com/wiki/%E6%8F%90%E8%B4%A7%E5%8D%95" target="_blank" rel="noopener">提货单</a>等各种票证单据都是证券。 – MBA智库百科</p></blockquote><p>书本上的定义为：发行人未来收入与资产的索取权。也就是所谓的本金加利息吧。</p><h4 id="债券是什么？"><a href="#债券是什么？" class="headerlink" title="债券是什么？"></a>债券是什么？</h4><p>债券是债务证券，它承诺在一个特定的时间段中进行定期支付。</p><blockquote><p><strong>债券(Notes)</strong>是政府、<a href="https://wiki.mbalib.com/wiki/%E9%87%91%E8%9E%8D%E6%9C%BA%E6%9E%84" target="_blank" rel="noopener">金融机构</a>、工商企业等机构直接向社会借债筹措资金时，向投资者发行，<a href="https://wiki.mbalib.com/wiki/%E6%89%BF%E8%AF%BA" target="_blank" rel="noopener">承诺</a>按一定<a href="https://wiki.mbalib.com/wiki/%E5%88%A9%E7%8E%87" target="_blank" rel="noopener">利率</a>支付利息并按约定条件偿还<a href="https://wiki.mbalib.com/wiki/%E6%9C%AC%E9%87%91" target="_blank" rel="noopener">本金</a>的债权债务凭证。 – MBA智库百科</p></blockquote><h4 id="利率是什么？"><a href="#利率是什么？" class="headerlink" title="利率是什么？"></a>利率是什么？</h4><p>利率是借款的成本或为借入资金支付的价格。</p><h3 id="股票市场"><a href="#股票市场" class="headerlink" title="股票市场"></a>股票市场</h3><p>普通股，通常简称为股票，代表持有者对公司的所有权。股票是对公司收益和资产的索取权。</p><p>在股票市场中，所交易的是对公司收益的索取权，即股票。</p><h2 id="为什么研究金融机构和银行？"><a href="#为什么研究金融机构和银行？" class="headerlink" title="为什么研究金融机构和银行？"></a>为什么研究金融机构和银行？</h2><p>银行与其它金融机构是金融市场能够运行的关键所在。没有它们，金融市场就无法将资金由存储者向右生产性投资机会的人转移。</p><h3 id="金融体系的结构"><a href="#金融体系的结构" class="headerlink" title="金融体系的结构"></a>金融体系的结构</h3><p>金融体系是由银行、保险公司、共同基金、财务公司、投资银行等不同类型的私人金融机构构成的复杂系统。所有金融机构都受到政府部门的严格监管。</p><p>为什么金融中介是运转良好的金融市场的关键因素？为什么是它们而非其他机构和个人向一些机构和个人提供贷款？为什么它们是经济中受到最严格监管的部门？</p><h3 id="银行与其它金融机构"><a href="#银行与其它金融机构" class="headerlink" title="银行与其它金融机构"></a>银行与其它金融机构</h3><p>银行是吸收存款和发放贷款的金融机构。然而，银行并非唯一重要的金融机构。</p><p>事实上，保险公司、财务公司、养老基金、共同基金和投资银行近年来的发展势头远远超过了银行。</p><p>它们为了获取利润是如何管理资产和负债的？监管形式是怎样的？为什么一些金融机构的发展要快于其它金融机构？</p><h3 id="金融创新"><a href="#金融创新" class="headerlink" title="金融创新"></a>金融创新</h3><p>即新的金融产品和服务的发展。</p><h3 id="金融危机"><a href="#金融危机" class="headerlink" title="金融危机"></a>金融危机</h3><p>所谓金融危机，是指金融市场出现混乱，并伴随着资产价格的暴跌以及众多金融机构和非金融机构的破产。这是资本主义经济体的一个重要特征。</p><p>为什么会产生金融危机？金融危机为什么会对经济产生如此严重的冲击？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;第一章-为什么？&quot;&gt;&lt;a href=&quot;#第一章-为什么？&quot; class=&quot;headerlink&quot; title=&quot;第一章 为什么？&quot;&gt;&lt;/a&gt;第一章 为什么？&lt;/h1&gt;&lt;h2 id=&quot;为什么研究金融市场？&quot;&gt;&lt;a href=&quot;#为什么研究金融市场？&quot; class=&quot;
      
    
    </summary>
    
    
      <category term="Books" scheme="http://notes-hongbo.top/tags/Books/"/>
    
      <category term="Amateur" scheme="http://notes-hongbo.top/tags/Amateur/"/>
    
  </entry>
  
  <entry>
    <title>Neural Networks and Deep Learning</title>
    <link href="http://notes-hongbo.top/2018/11/10/Neural-Network-and-Deep-Learning/"/>
    <id>http://notes-hongbo.top/2018/11/10/Neural-Network-and-Deep-Learning/</id>
    <published>2018-11-10T14:06:47.000Z</published>
    <updated>2018-11-16T03:06:12.639Z</updated>
    
    <content type="html"><![CDATA[<p>本文用于记录学习Coursera中Neural Networks and Deep Learning课程的笔记</p><a id="more"></a><h1 id="第一周"><a href="#第一周" class="headerlink" title="第一周"></a>第一周</h1><p>why is deep learning taking off?  </p><p>Beceuse deep learning could handle large set of data to promopte itself while logistic regression, SVM and something else can’t.</p><hr><p>Either your intuitions are good or they’re not. </p><ul><li>If your intuitions are good, you should follow them and you’ll eventually be successful. If your intuitions are not good, it doesn’t matter what you do. There is not point not trusting them.</li><li>never stop programming</li><li>read enough so you start developing intuitions, and then trust your instuitions and go for it. Don’t be too worried if everybody else says it’s nonsense.</li></ul><p>Geoffrey Hinton</p><h1 id="第二周"><a href="#第二周" class="headerlink" title="第二周"></a>第二周</h1><ol><li><p>some changes compared to the previous video of Andre </p><ul><li>the matrix of training set $X$ has the size $n\times m$, and the label of it has the size $1 \times m$</li><li>there’s no plus one row of $X$ matrix for the bias value, and we are going to seperate it from teh bias</li></ul></li><li><p>computation graph for how to compute the derivatives of some function</p></li><li><p>vectorized computation is much faster than unvectorized version in Python</p><p>and the method to get time running time of one programm is to use <code>time.time()</code> method in package <code>time</code>. When we use it, then we will get the current time of programm. Mark <code>tic</code> as the time before we run calculating and <code>toc</code> means after calculation, then <code>1000*(toc-tic)</code> means the times used to calculate in <code>ms</code>.</p><p>the reason for that is because vectorized calculation make use of parallelization. </p></li><li><p>when we add some real number to some vector or matrix then it will be handled to a matrix full of real number, which is called “Boardcasting”</p></li><li><p>the deduction of the derivatives for logistic regression</p><p><img src="/Users/qinhongbo/Desktop/figure1.png" alt=""></p></li><li><p>the broadcasting function not only transform a single real number into a matrix that matches the matrix add or substract it, but also it could transform a vector to some matrix that matches the matrix make some operations with it.</p></li><li><p>the parameter <code>axis</code> in <code>sum</code> method means to calculate the sum vertically(0) or horizontally(1).</p></li><li><p>tip when work with numpy</p><p>it is better to deal with 2 rank array of numpy array rather than rank 1 array</p><p>because rank 1 array is either a row vector nor a column vector; and the way to create it is something like <code>a = np.random.randn(5)</code>. While the way to create a rank 2 array is <code>a = np.random.randn(5, 1)</code>. Also, it is good to use <code>a.shape(row, col)</code> regularly.</p></li><li><p><strong>What you need to remember:</strong></p><p>Common steps for pre-processing a new dataset are:</p><ul><li>Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …)</li><li>Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)</li><li>“Standardize” the data</li></ul></li><li><p>My <a href="http://notes-hongbo/html/" target="_blank" rel="noopener">jupyter notebook</a> while watching this week’s video</p></li></ol><h1 id="第三周"><a href="#第三周" class="headerlink" title="第三周"></a>第三周</h1><ol><li><p>when we are talking about the layers of neural network, what are we talking about?</p><p>The input layer shouldn’t be counted. So the first layer is the first hidden layer. The reason for this is that in Python subscript counts from zero.</p></li><li><p>some activation of neural network</p><ul><li><p>sigmoid(if binary classification)</p></li><li><p>tanh = $\displaystyle \frac{e^{x} - e^{-x}}{e^x + e^{-x}}$</p><p>$g’(z) = \displaystyle 1 - (tanh(z))^2$</p></li><li><p><strong>ReLU</strong>(default choice) = $max(z, 0)$</p></li><li><p>leaky ReLU = $max(0.01z, z)$</p></li></ul></li><li><p>why do we use linear activation function? Because in this case, finally we will get a linear regression algorithm. It is very clear if we write down the formulas.</p></li></ol><h1 id="第四周"><a href="#第四周" class="headerlink" title="第四周"></a>第四周</h1><ol><li><p>some notations of deep neural network(mark the input layer as layer 0, the first hidden layer as layer 1)</p><ul><li>$n^{ [l]}$ denotes the units in layer $l$</li><li>$a^{[l]}$ denotes the activations in layer $l$</li></ul></li><li><p>some formular in deep network, and there must be one for-loop to make the forward propagation</p><ul><li>$Z^{[l]} = W^{[l]}A^{[l - 1]} + b^{[l]}$</li><li>$A^{[l]} = g^{[l]}(Z^{[l]})$</li></ul></li><li><p>how to get your matrix dimensions right?</p><ul><li>$W^{[l]}: \ (n^{[l]}, n^{[l - 1]})$</li><li>$b^{[l]}: \ (n^{[l]}, 1)$</li></ul></li><li><p>why deep representations ?</p><ul><li><p>we can think of neural network that it will compose the small element into something more abstract. </p><p>For example, when we input pixels of a image, the first layer maybe deal with these pixels to form some lines; then second layer maybe deal with these line to form some features of face; afterwards the deeper layer will deal with these features to see if it recognize the face composed by these features.</p></li><li><p>Circuit theory and deep learning: There are functions u can compute with a “small” N-layer deep neural network that shallower networks require exponentially more hidden units to computes.</p><p>I think the tuition behind this is to solve repeatedly subproblem only once which is very same with dynamic programming.</p></li></ul></li><li><p>backward propagation for layer $l$</p><p>Input: $da^{[l]}$</p><p>Ourtput: $da^{[l - 1]}, dW^{[l]}, db^{[l]}$</p><p>Calculation:$\begin{cases}dz^{[l]} = da^{[l]}*g^{‘[l]}(z^{[l]}) \ \ dw^{[l]} = dz^{[l]}\cdot a^{[l -1]} \ \ db^{[l]} = dz^{[l]}  \\ da^{[l - 1]} = w^{[l]T}\cdot dz^{[l]}\end{cases}$</p></li><li><p>a brief to hyperparameters</p><p>the parameters that control the final parameter that we use to predict some examples</p><p>hyperparameters: </p><ul><li>learning rate</li><li>iterations</li><li>hidden layer </li><li>hidden unit</li><li>choice of activation funciton</li></ul><p>parameters:</p><ul><li>weight matrix</li><li>bias</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文用于记录学习Coursera中Neural Networks and Deep Learning课程的笔记&lt;/p&gt;
    
    </summary>
    
      <category term="Deep Learning" scheme="http://notes-hongbo.top/categories/Deep-Learning/"/>
    
    
      <category term="AI" scheme="http://notes-hongbo.top/tags/AI/"/>
    
      <category term="Coursera" scheme="http://notes-hongbo.top/tags/Coursera/"/>
    
  </entry>
  
  <entry>
    <title>流浪猫Bob</title>
    <link href="http://notes-hongbo.top/2018/11/10/%E6%B5%81%E6%B5%AA%E7%8C%ABBob/"/>
    <id>http://notes-hongbo.top/2018/11/10/流浪猫Bob/</id>
    <published>2018-11-10T06:23:07.000Z</published>
    <updated>2018-11-11T03:20:10.015Z</updated>
    
    <content type="html"><![CDATA[<p>这是上个周六去电影院看的一部电影。</p><p>经过一周的时间，发现越咀嚼越有滋味，遂记录所想。</p><a id="more"></a><p>电影所讲的，是一名毒瘾患者在戒毒的道路上跌跌撞撞的故事。主人公能做的只是街头卖艺，这是他唯一经济来源。平日里流落在伦敦的街头，居无定所，无依无靠。</p><p>可是我仍然觉得他的人生很美好。因为他能收到很多人的友善，因为他能获得很多人的敞开心扉，因为他面前的生活十分温暖。</p><p>不禁回想起来妈妈对我想要出国读书的担忧 – “孤独无依，太苦了”。可是在国内又何尝不是这样呢？每日的竞争我倒是早已习以为常，不过是看谁的自制力强一点，看谁肯下多些功夫而已。真正忍受不了的，是没有一个人肯对自己敞开心扉。</p><p>虽孤身一人，吾往矣。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是上个周六去电影院看的一部电影。&lt;/p&gt;
&lt;p&gt;经过一周的时间，发现越咀嚼越有滋味，遂记录所想。&lt;/p&gt;
    
    </summary>
    
    
      <category term="life" scheme="http://notes-hongbo.top/tags/life/"/>
    
  </entry>
  
  <entry>
    <title>BP Neural Network</title>
    <link href="http://notes-hongbo.top/2018/11/05/BP-Neural-Network/"/>
    <id>http://notes-hongbo.top/2018/11/05/BP-Neural-Network/</id>
    <published>2018-11-05T15:02:27.000Z</published>
    <updated>2018-11-05T15:23:56.419Z</updated>
    
    <content type="html"><![CDATA[<p>因为是神经网络中十分经典的算法，故特意开设一篇记录自己对其的理解，伴随着学习的深入将不断完善。</p><a id="more"></a><p>前向传输时使用sigmoid函数作为激活函数，输出层使用softmax作为输出函数。</p><p>代价函数使用均方差MSE函数$J = \displaystyle \frac{1}{2}\sum_{i = 1}^{M}(t_i - y_i)^2$。使用随机梯度降SDG方法进行优化。</p><p>主要框架的伪代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backPropNeuralNetwork</span><span class="params">(training_data, epochs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(epochs): <span class="comment"># 迭代次数</span></span><br><span class="line">        shuffle training data <span class="comment"># 打乱数据顺序</span></span><br><span class="line">        get <span class="string">"mini_batches"</span> used to train the neural network<span class="comment">#将随机后的数据分为多个batch</span></span><br><span class="line">        <span class="keyword">for</span> mini_batch <span class="keyword">in</span> mini_batches: <span class="comment"># 对于每一个mini_batch对神经网络进行训练</span></span><br><span class="line">            update_mini_batch(mini_batch)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_mini_batch</span><span class="params">(mini_batch, learning_rate)</span>:</span></span><br><span class="line">    initialize the delta of weights <span class="keyword">and</span> biases matrix</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> mini_batch:</span><br><span class="line">        back propogation <span class="comment"># 反向传播算法计算代价函数关于各个参数的偏导数</span></span><br><span class="line">        update the delta of weights <span class="keyword">and</span> biases matrix </span><br><span class="line">    update the weights <span class="keyword">and</span> biases matrix based on the delta matrix</span><br></pre></td></tr></table></figure><p>其中反向传播算法计算偏导的公式推导如下</p><p>代价函数$J = \displaystyle \frac{1}{2}\sum_{i = 1}^{M}(t_i - y_i)^2$</p><p>定义误差$\delta_j^l = \displaystyle \frac{\partial J}{\partial z_j^l} $</p><p>公式一：对于输出层 </p><p>$\begin{cases} \displaystyle \frac{\partial J}{\partial z_j^L}=\sum_k\frac{\partial J}{\partial a _k^L}\frac{\partial a_k^L}{\partial z_j^L} = \frac{\partial J}{\partial a_j^L}\frac{\partial a_j^L}{\partial z_j^L} \\ \displaystyle \frac{\partial J}{\partial a_j^L}  = \frac{\partial (\frac{1}{2}(y_j - t_i)^2)}{\partial t_i} = t_k - y_k \\ \displaystyle \frac{\partial a_j^L }{\partial z_j^L} = \text{softmax}’(z_j) = y_i [(y_i - t_i) + \sum_{j = 1}^M (t_j - y_j)y_j] \\ \displaystyle \delta^L_j = (t_j - y_j)[(y_j - t_j) + \sum_{i = 1}^{M}(t_i - y_i)y_i]  \end{cases}$</p><p>公式二：对于隐藏层</p><p>$\begin{cases} \displaystyle \delta_j^l = \frac{\partial J}{ \partial z_j^l} = \sum_k \frac{\partial J}{\partial z_k^{l + 1}} \frac{\partial z_k^{l + 1}}{\partial z_j ^l} = \sum_k \frac{\partial z_k^{l + 1}}{\partial z_j ^l}\delta_k^{l + 1} \\ \displaystyle \frac{\partial z_k^{l + 1}}{\partial z_j^l} = \sum_k w_{kj}^{l + 1}\sigma’(z_j^l) \\ \displaystyle \delta _j^l = \sum_kw_{kj}^{l+1}\delta_k^{l + 1}\text{sigmoid}’(z_j^l)  \end{cases}$</p><p>公式三：对于偏置量$\Delta b = \displaystyle \frac{\partial J}{\partial b}= \frac{\partial J}{\partial z}\frac{\partial z}{\partial b} = \delta$</p><p>公式四：对于权重 $\Delta w_{ji}^l = \displaystyle \frac{\partial  J}{\partial w_{ji}^l} = \frac{\partial J}{\partial z_j^l}\frac{\partial z_j^l}{\partial w_{ji}^l} = \delta^l a_i^{l - 1} $</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为是神经网络中十分经典的算法，故特意开设一篇记录自己对其的理解，伴随着学习的深入将不断完善。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Algorithm" scheme="http://notes-hongbo.top/tags/Algorithm/"/>
    
      <category term="AI" scheme="http://notes-hongbo.top/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning notes in Coursera</title>
    <link href="http://notes-hongbo.top/2018/10/30/Machine-Learning-notes%20in-Coursera/"/>
    <id>http://notes-hongbo.top/2018/10/30/Machine-Learning-notes in-Coursera/</id>
    <published>2018-10-30T03:46:38.000Z</published>
    <updated>2018-11-10T08:19:51.778Z</updated>
    
    <content type="html"><![CDATA[<p>本文用于记录学习Coursera中Machine Learning课程的笔记</p><a id="more"></a><h1 id="第一周"><a href="#第一周" class="headerlink" title="第一周"></a>第一周</h1><ol><li><p>regression: predict continuous valued output</p></li><li><p>supervised learning: right answer given</p></li><li><p>benign tumor | malignant tumor</p><p>market segmentation</p></li><li><p>监督学习及其分类</p><blockquote><p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p><p>Supervised learning problems are categorized into “regression” and “classification” problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.</p></blockquote></li><li><p>unsupervised learning</p></li><li><p>函数h 是一个约定俗成的函数</p><p>表示的内容为hypotheses，也就是经过算法学得的函数</p><p>$h_{\theta}(x) = \theta_{0} + \theta _{1}x$ 表示参数变量为$\theta$，自变量为$x$的函数</p><p>一般会简写为$h(x) = \theta_{0} + \theta _{1}x$ </p></li><li><p>cost function $J(\theta_{0}, \theta_{1}) = \displaystyle \frac{1}{2m}\sum_{i=1}^{m}(h(x^{(i)}) - y^{(i)})^2$</p><p>表示代价函数的参数为theta </p><p>最小化代价函数的符号为 $\underset{\theta_{0}, \theta_{1}}{\text{minimize}}J(\theta_{0}, \theta_{1})$</p></li><li><p>梯度下降法在进行参数的更新时，该层的参数必须使用上一层的参数进行更新，而不可以使用本层的参数</p><p>即在进行某个参数的更新时，必须保证使用的参数都是上一层的</p><p>使用temp0 暂存 theta0 的数据</p></li><li><p>关于梯度下降的公式 $\theta_{i} := \theta_{i} - \alpha \displaystyle \frac{\partial}{\partial \theta_{i}}J(\theta_{i})$</p><p>为什么后面的符号为减号而不是加号</p><p>总的来说，梯度下降法是寻找最小值的一种收敛法</p><p><img src="figure1.png" alt=""></p><p>从该图来说，如果选择50作为起始点，那么因为是为了寻找较小值，所以需要向左边移动，因此要减去该点对应的正值导数的适当比例</p><p>实际上，梯度法求极值对应的自变量坐标，其中的导数不过是提供了一个方向而已</p><p>前面还有fancy的参数叫做学习率，其实也就是一次的步长</p><p>按理说学习率应该越小越好，因为梯度法当出现因学习率过大导致跨越了最优值时，该参数就不合适了。同时考虑到想要迭代次数尽可能小，所以学习率又需要适当大。可以说这里就是需要所谓的调参。</p><p>但是需要注意的是，如果学习率过小，并且代价函数最优解附近的导数都比较小，那么将会出现每一次迭代走过的步越来越小，导致还没有到达最优解就已经停止收敛。(这个要参照退出循环的条件)</p><p>所以这个参数的选择还是有一定的考究的。</p><p>如果目前已经到达了最优解，那么因为该点的导数为0，所以该值不会进行更新</p></li><li><p>线性回归任务的代价函数一定是凸函数!!!</p></li></ol><h1 id="第三周"><a href="#第三周" class="headerlink" title="第三周"></a>第三周</h1><p>收获：总结出了将运算向量化的步骤！深入理解了对数回归！</p><ol><li><p>为什么最大似然估计必定是凸函数</p></li><li><p>关于为什么在代价函数中总是约定$h_{\theta}(x)= \displaystyle \frac{1}{1 + e^{-\theta ^{T}x}}$，其中后面自然指数的幂次总是这样的形式？</p><p>此时认为$\theta $和$x$都是列向量</p><p>可是在实际应用中，总是将一个样本中的数据放到一行中进行展示，最后一列表示target。所以此处存在一个别扭的转换。</p></li><li><p>扩展了一些收敛迭代方法; 建议直接调用库函数，而不要自己去实现</p><ul><li>conjugate gradient</li><li>BFGS</li><li>L-BFGS</li></ul></li><li><p>直接使用库函数会使得难以调试，但是带来的效率是值得的</p></li><li><p>针对多分类任务，我们设置多个不同的“假设”$h_{\theta}^{(i)}(x) = P(y = i | x; \theta)$</p><p>表示目前在分类第i个类别，使用$\theta$作为参数，x作为自变量</p></li><li><p>假设在数据中我们有k个需要抽取出来的特征，那么我们就需要设置k个分类器</p><p>这是因为每次筛选数据的时候，并不是每进行一步就将筛选出来的数据剔除</p><p>而是针对每一种特征训练出来一种分类器，共需要k个分类器</p></li><li><p>逻辑回归 - 我的理解</p><p>关于为什么使用该函数$\displaystyle \frac{1}{1 + e^{-\theta ^T x}}$ ？ 是因为该函数可导连续，并且可以很好地从原点将坐标系分为两部分</p><p>insight：归根结底，是对$-\theta^T x$的拟合  =&gt; 如果大于0，那么 预测为正例，否则为反例。此时传入的参数可以为非线性的，即$x^2, x^3, x^4 …$此类，使其可以完成非线性任务。</p></li><li><p>处理过拟合的两种办法</p><ul><li><p>减少参数数量 - 可以人为选择保留的参数；可以使用模型选择算法，判断哪些参数保留，哪些扔掉</p><p>该方法的缺点是也许所有的参数都有用，但是仍然会把它扔掉；</p><p>归根到底还是算法或者选择不当，如果把这个因素修改完成，那么一样可以达成过拟合的目的    </p></li><li><p>正则化 - 保留所有参数，但是减少参数的影响；适用于有很多个参数同时每个参数都有作用</p></li></ul></li><li><p>正则化实际上就是修改代价函数，来使得某些参数应该尽可能偏小</p><p>具体的方法是在代价函数后加上一些类似$1000\theta_{i}^2$这样的项，如此一来就可以达到减小该项影响的作用</p><hr><p>正则化中的$\lambda$是为了均衡两个目标 - 与训练集更匹配bias &amp; 函数图形更简单variance</p></li><li><p>在正规方程中使用正规化，甚至可以将矩阵转化为绝对可逆</p></li><li><p>关于运算的向量化</p><p>$$\theta_j = \displaystyle \sum_{i = 1} ^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$    &lt;=&gt;  <code>grad = X&#39; * (sigmoid(X * theta) - y) / m</code></p><p>上式在起初学习的时候我不明白应该如何进行计算，于是使用了两个for循环来处理</p><p>但是如果仔细考察的话，可以发现使用矩阵运算即可完成</p><p>之前我习惯把求和以及前面的括号看成一团，后面的看成一部分，但是实际上要把求和号后面的看成一个整体</p><hr><p>我决定对这个东西做一个总结，这其中必定存在某种普遍使用的结论</p><ul><li>前面的求和号，表示括号中的元素和后面的x必定分别属于矩阵的某行某列</li><li>注意到i的变化是从小到大，所以相对于矩阵运算，必定是从左到右、从上到下</li><li>如果将括号中的元素视为一个列向量的话，那么x必定是从左到右；注意到其j下标是不变的，所以x矩阵中的一行，表示的是每个样本数据的第j个数据</li></ul><p>搞定！</p></li><li><p>octave中的size函数，第二个参数用来标记返回的是行数还是列数</p></li><li><p>在使用正则化时，注意代价函数不计算常数项的参数$\theta_0$</p><p>同时在更新<code>theta(2:n)</code>的时候，仍然可以使用向量化运算，注意将n维中的第一维删除掉</p></li></ol><h1 id="第四周"><a href="#第四周" class="headerlink" title="第四周"></a>第四周</h1><ol><li><p>神经网络产生的背景</p><p>当使用多项式假设时，面对多个特征，如果要暴力组合所有的配对方案，那么将会产生数目巨大的feature；而如果使用较小的feature，那么就会产生欠拟合的问题</p></li><li><p>每一个输入以及输出都从1开始编号，每一层都特殊设置一个偏移量，该偏移量从0开始编号</p><p>也就是对应的阈值</p><p>input layer + hidden layer + output layer</p></li><li><blockquote><p>机器学习可以看做是数理统计的一个应用，在数理统计中一个常见的任务就是拟合，也就是给定一些样本点，用合适的曲线揭示这些样本点随着自变量的变化关系。</p><p>深度学习同样也是为了这个目的，只不过此时，样本点不再限定为(x, y)点对，而可以是由向量、矩阵等等组成的广义点对(X,Y)。而此时，(X,Y)之间的关系也变得十分复杂，不太可能用一个简单函数表示。然而，人们发现可以用多层神经网络来表示这样的关系，而多层神经网络的本质就是一个多层复合的函数。</p><p>作者：Anonymous</p><p>链接：<a href="https://www.zhihu.com/question/27239198/answer/89853077" target="_blank" rel="noopener">https://www.zhihu.com/question/27239198/answer/89853077</a></p></blockquote></li><li><p>for the parameter $\theta$ , it is a matrix with three dimensions</p><p>suppose that now we are at i-th layer, then $\theta^{(i)}$ have a dimension  of $size(s_{i + 1}) \times (size(s_{i}) + 1)$, and $x^{(i)}$ has the dimension of $(size(s_i) + 1) \times 1$</p><p>because in the future we are going to calculate $z^{(i+1)} = \theta^{(i)} * x^{(i)}$ where $x^{(i)} = a^{(i)}$,</p><p>after we get the value of $z$ and put it into the sigmoid function, we get $a^{(i)} = g(z^{(i)})$</p></li><li><p>in the every layer, we can regard the parameter as one function which is learned by the nodes before it</p><p>so our final result is made of many functions to evaluate the aim function.</p></li><li><p>network architectures refer to how the different neurons are connected to each other.</p></li><li><p>notes about <code>octave</code></p><ul><li><p><code>.*</code> will return a vector rather than a scalar value</p></li><li><p><code>[a, b] = max(A, [], 2)</code> will return the information about this matrix</p><p>the first return parameter is maximum value in every line</p><p>the second return parameter is index of every maximum value in every line</p><p>in the <code>max</code> function, the first parameter is the matrix we concerned, the second is the default value which shouldn’t be changed, the third parameter represents to search according to column-1, or row-2</p></li></ul></li></ol><h1 id="第五周"><a href="#第五周" class="headerlink" title="第五周"></a>第五周</h1><ol><li><p>The cost function of neural networks:</p><p>$J(\Theta) = \displaystyle - \frac{1}{m}\sum_{i = 1}^{m} \sum_{k = 1}^K[y_k^{(i)}log((h_{\Theta}(x^{(i)}))_k) + (1 - y_k^{(i)}) log(1 - (h_{\Theta}(x^{(i)}))<em>k)] + \frac{\lambda}{2m}\sum</em>{i = 1}^{L - 1}\sum_{i = 1}^{s_l}\sum_{j = 1}^{s_l + 1}(\Theta_{j, i}^{(l)})^2$</p><p>We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, before the square brackets, we have an additional nested summation that loops through the number of output nodes.</p><p>In the regularization part, after the square brackets, we must account for multuple theta matrices. The number of columns in our current theta matrix is equal to the number of nodes in our current layer(including the bias unit). The number of rows in our current theta matrix is euqal to the number of nodes in the next layer(excluding the bias unit). </p><p>Note:</p><ul><li>the double sum simply adds up the logistic regression costs calculated for each cell in the output layer </li><li>the triple sum simply adds up the squares of all the individual $\Theta$s in the entire network</li><li>the i in the triple sum does not reger to training example, but the part before it does!</li><li>the first part of this funciton is all $K$ logistic regression added up separately.</li></ul></li><li><blockquote><p>如何直观地解释 backpropagation 算法？ - Anonymous的回答 - 知乎<br><a href="https://www.zhihu.com/question/27239198/answer/89853077" target="_blank" rel="noopener">https://www.zhihu.com/question/27239198/answer/89853077</a></p></blockquote><p>观后感：BP神经网络就是链式法则</p><p>该文对于理解BP神经网络有极大的帮助</p><p>看到评论里有人表示这个其实是动态规划，真是naive</p><p>因为error的限制，只能从输出层向输入层传递，另外需要每次计算出同层的所有结点再进行传递，这大概就是BP神经网络的框架</p></li><li><p>BP神经网络的公式推导</p><p><a href="https://www.cs.swarthmore.edu/~meeden/cs81/s10/BackPropDeriv.pdf" target="_blank" rel="noopener">https://www.cs.swarthmore.edu/~meeden/cs81/s10/BackPropDeriv.pdf</a></p></li><li><p>new instructions of octave</p><p>if we have many matrices of different scales, and want to unroll them into one datastructure, then we can do it by <code>thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]</code></p><p>and get the matrices back by</p><p><code>Theta1 = reshape(thetaVector(1:110),10,11);</code></p><p><code>Theta2 = reshape(thetaVector(111:220),10,11);</code></p><p><code>Theta3 = reshape(thetaVector(221:231),1,11);</code></p></li><li><p>gradient checking, which is to check the whether the rough derivative function could get a similiar value in regard to the value we get from the derivative function of BP algorithm</p></li><li><p>神经网络的初始化参数问题 - 为什么不可以像回归问题一样全部置0？</p><p><img src="figure2.png" alt=""></p><p>考虑给定的神经网络，其中结点1, 2, 3在输入层，结点4, 5在隐含层，结点6位于输出层</p><p>假定：输入各不相同；初始化全部参数为0。</p><ul><li><p>第一次正向传播过程中，后面结点上激活值均为0.5</p></li><li><p>第一次反向传播过程中，结点4, 5的输入由于相同，所以它们学得的权重相同；同时由于输入层到隐含层的参数在计算时，它们的输入也都相同，所以学得的参数也都相同</p></li><li>第二次正向传播过程中，结点4, 5的输入相同，所以激活值相同，进而得到输入</li><li>第二次反向传播过程中，结点4, 5学得的权重仍然相同；同时结点1学得的两个权重相同、结点2学得的两个权重相同、结点3学得的两个权重相同<strong>(这是因为权重的学习与三个量相关，一个是该结点的激活值，一个是上一层的误差，一个是两层之间的权重)</strong></li></ul></li><li><p>作业总结</p><ul><li><p>因为octave类似python没有先声明后使用的规则，所以会出现一种很神奇的BUG - 变量名拼错</p><p>这种BUG在这种语言里面实在是危险，出现的时候不会有任何的报错信息</p></li><li><p>梯度降矩阵的规模与$\Theta$矩阵的规模一致，将来更新的时候也就是更新这些参数</p></li></ul></li></ol><h1 id="《神经网络与深度学习》"><a href="#《神经网络与深度学习》" class="headerlink" title="《神经网络与深度学习》"></a>《神经网络与深度学习》</h1><p>吴恩达的课程解释得太浅，学得的大概只是一个神经网络的框架</p><p>希望能够借助这本书来对神经网络有一个更深入的理解</p><h2 id="人工神经元模型"><a href="#人工神经元模型" class="headerlink" title="人工神经元模型"></a>人工神经元模型</h2><h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p><img src="figure3.png" alt=""></p><p>示例中的感知机有三个输入，$x_1, x_2, x_3$</p><p>$$output = \displaystyle \begin{cases} 0 &amp; \text{if } \sum_jw_jx_j \leq \text{threshold} \ 1 &amp; \text{if} \sum_j w_j x_j &gt; \text{threshold }\end{cases}$$</p><p>我们可以把偏置看成一种表示让感知机输出1有多容易的估算。</p><h3 id="S型神经元"><a href="#S型神经元" class="headerlink" title="S型神经元"></a>S型神经元</h3><p>如果对权重的微小改动能够仅仅引起输出的微小变化，那么我们可以利用这一事实来修改权重和偏置，让我们的网络能够表现得像我们想要的那样。我们重复这个工作，反复改动权重和偏置来产生更好的输出。这时网络就在学习。</p><p>可是问题在于网络中单个感知机上一个权重或偏置的微小改动有时候会引起那个感知机的输出完全翻转。</p><p>我们可以引入一种称为S型神经元的模型来克服这个问题。</p><p><img src="figure3.png" alt=""></p><p>正如一个感知机，S型神经元有多个输入，$x_1, x_2, …$。但是这些输入可以取0和1中的任意值，而不仅仅是0或1.其输出现在不是0或1，而是$\sigma(w \cdot x + b)$，其中$\sigma$被称为S型函数，定义为$\displaystyle \sigma(z) = \displaystyle \frac{1}{1 + e^{-z}}$</p><p>$\sigma$的平滑意味着权重和偏置的微小变化，即$\Delta w_j$和$\Delta b$，会从神经元产生一个微小的输出变化$\Delta \text{output}$。实际上，微积分告诉我们</p><p>$$\displaystyle \Delta \text{output} \approx \sum_j \frac{\partial\text{output}}{\partial w_j} \Delta w_j + \frac{\partial\text{output}}{\partial b} \Delta b$$</p><h2 id="手写数字识别-为什么不用4个输出表示二进制数字完成任务？"><a href="#手写数字识别-为什么不用4个输出表示二进制数字完成任务？" class="headerlink" title="手写数字识别, 为什么不用4个输出表示二进制数字完成任务？"></a>手写数字识别, 为什么不用4个输出表示二进制数字完成任务？</h2><p>最终的判断是基于经验主义的：我们可以实验两种不同的⽹络设计，结果证明对于这个特定的问题而⾔，10 个输出神经元的神经⽹络⽐ 4 个的识别效果更好。但是令我们好奇的是为什么使⽤ 10 个输出神经元的神经⽹络更有效呢。有没有什么启发性的⽅法能提前告诉我们⽤ 10 个输出编码⽐使⽤ 4 个输出编码更有好呢？</p><p>为了理解为什么我们这么做，我们需要从根本原理上理解神经⽹络究竟在做些什么。⾸先考虑有 10 个神经元的情况。我们⾸先考虑第⼀个输出神经元，它告诉我们⼀个数字是不是 0。它能那么做是因为可以权衡从隐藏层来的信息。隐藏层的神经元在做什么呢？假设隐藏层的第⼀个神经元只是⽤于检测如下的图像是否存在：</p><p><img src="figure4.png" alt=""></p><p>为了达到这个⽬的，它通过对此图像对应部分的像素赋予较⼤权重，对其它部分赋予较小的权重。同理，我们可以假设隐藏层的第⼆，第三，第四个神经元是为检测下列图⽚是否存在：</p><p><img src="figure5.png" alt=""></p><p>如果所有隐藏层的这四个神经元被激活那么我们就可以推断出这个数字是 0。当然，这不 是我们推断出 0 的唯⼀⽅式 —— 我们能通过很多其他合理的⽅式得到 0 （举个例⼦来说，通过 上述图像的转换，或者稍微变形）。但⾄少在这个例⼦中我们可以推断出输⼊的数字是 0。</p><p>假设神经⽹络以上述⽅式运⾏，我们可以给出⼀个貌似合理的理由去解释为什么⽤ 10 个输 出而不是 4 个。如果我们有 4 个输出，那么第⼀个输出神经元将会尽⼒去判断数字的最⾼有效 位是什么。把数字的最⾼有效位和数字的形状联系起来并不是⼀个简单的问题。很难想象出有 什么恰当的历史原因，⼀个数字的形状要素会和⼀个数字的最⾼有效位有什么紧密联系。</p><hr><p>上述只是一个猜测… 有一些勉强的感觉… 可能这就是所谓玄学吧</p><h2 id="为什么代价函数是二次代价？而不是直接最大化正确分类的数量？"><a href="#为什么代价函数是二次代价？而不是直接最大化正确分类的数量？" class="headerlink" title="为什么代价函数是二次代价？而不是直接最大化正确分类的数量？"></a>为什么代价函数是二次代价？而不是直接最大化正确分类的数量？</h2><p>这时因为被正确分类的图像数量所关于权重和偏置的函数并不是一个平滑的函数。大多情况下，对权重和偏置做出的微小变动完全不会影响被正确分类图像的数量。这回导致我们很难去解决如何改变权重和偏置来取得性能的提升。</p><h2 id="梯度下降法的直观理解"><a href="#梯度下降法的直观理解" class="headerlink" title="梯度下降法的直观理解"></a>梯度下降法的直观理解</h2><p>我们想象有⼀ 个小球从⼭⾕的斜坡滚落下来。我们的⽇常经验告诉我们这个球最终会滚到⾕底。也许我们可 以⽤这⼀想法来找到函数的最小值？我们会为⼀个（假想的）球体随机选择⼀个起始位置，然 后模拟球体滚落到⾕底的运动。我们可以通过计算 C 的导数（或者⼆阶导数）来简单模拟——这些导数会告诉我们⼭⾕中局部“形状”的⼀切，由此知道我们的球将怎样滚动。</p><h2 id="随机梯度下降法的直观理解"><a href="#随机梯度下降法的直观理解" class="headerlink" title="随机梯度下降法的直观理解"></a>随机梯度下降法的直观理解</h2><p>我们可以把随机梯度下降想象成一次民意调查：在一个小批量数据上采样比对一个完整数据集进行梯度下降分析要容易得多，正如进行一次民意调查比举行一次全民选举要更容易。</p><p>在计算量和迭代次数上面，SGD与GD没有差别，但是在一次迭代中SGD可能会更新很多次，因此会比GD收敛得更快，这也是平时所说的SGD比GD快的意思。</p><h2 id="BP神经网络公式的直观理解"><a href="#BP神经网络公式的直观理解" class="headerlink" title="BP神经网络公式的直观理解"></a>BP神经网络公式的直观理解</h2><p>回忆一下sigmoid函数，当$\sigma(z_j^L)$近似微0或者1的时候，该函数变得非常平。这时$\sigma^\prime (z_j^L) \approx 0$。所以如果输出神经元处于低激活值或者高激活值时，最终层的权重学习缓慢。这样的情形，我们常常称输出神经元已经饱和了，并且权重学习也会终止。类似的结果对于输出神经元的偏置也是成立的。</p><h1 id="第六周"><a href="#第六周" class="headerlink" title="第六周"></a>第六周</h1><ol><li><p>We can promote the performance of out machine learning algorithms by </p><ul><li>Getting more training examples</li><li>Trying smaller sets of features</li><li>Trying additional features</li><li>Trying polynomial features</li><li>Increasing or decreasing λ</li></ul><p>However, it is important to decide which measure to take to propmote our algorithm because any of them is time-costing.</p></li><li><p>A hypothesis may have a low error for the training examples but still be inaccurate because of overfitting. Thus, to evaluate a hypothesis, given a dataset of training examples, we can split up teh data into two sets: a training set and a test set. </p></li><li><p>Given many models with different polynomial degrees, we can use a systematic approach to identify the ‘best’ function. In order to choose the model of your hypothesis, you can test each degree of polynomial and look at the error result.</p><p>One way to break down our dataset into the three sets is:</p><ul><li>Training set: 60%</li><li>Cross validation set: 20%</li><li>Test set: 20%</li></ul><p>We can now calculate three separate error values for the three different sets using the following method:</p><ol><li>Optimize the parameters in Θ using the training set for each polynomial degree.</li><li>Find the polynomial degree d with the least error using the cross validation set.</li><li>Estimate the generalization error using the test set with $J_{test}(\Theta^{(d)})$, (d = theta from polynomial with lower error);</li></ol><p>This way, the degree of the polynomial d has not been trained using the test set.</p><hr><p>为了使得模型的generalization能力更强，将数据分为两部分，一部分用于训练(训练集和验证集)，另一部分用于测试。</p><p>训练集的数据用于训练模型，验证集的数据用于选择模型(如神经网络的结构、回归模型中的幂次等)，测试集的数据用于测试模型的performance。</p><p>一般来说validation上的cost会比test上的cost要小，这是因为前者相对于后者多了一些表示模型的参数。</p></li><li><p>The <em>bias</em> is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).</p><p>The <em>variance</em> is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting).</p></li><li><p>The training error will tend to <strong>decrease</strong> as we increase the degree d of the polynomial.</p><p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase d up to a point, and then it will <strong>increase</strong> as d is increased, forming a convex curve.</p><p><strong>High bias (underfitting)</strong>: both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ will be high. Also, $J_{CV}(\Theta) \approx J_{train}(\Theta)$.</p><p><strong>High variance (overfitting)</strong>: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be much greater than $J_{train}(\Theta)$.</p><p><img src="figure6.png" alt=""></p></li><li><p>How do we choose our parameter \lambdaλ to get it ‘just right’ ? In order to choose the model and the regularization term λ, we need to:</p><ol><li>Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24});</li><li>Create a set of models with different degrees or any other variants.</li><li>Iterate through the λs and for each λ go through all the models to learn some Θ.</li><li>Compute the cross validation error using the learned Θ (computed with λ) on the $J_{CV}(\Theta)$ <strong>without</strong> regularization or λ = 0. That’s because we have got the model parameters with the effect of regularization.</li><li>Select the best combo that produces the lowest error on the cross validation set.</li><li>Using the best combo Θ and λ, apply it on $J_{test}(\Theta)$ to see if it has a good generalization of the problem.</li></ol></li><li><p>learning curves</p><p><strong>Experiencing high bias:</strong></p><p><strong>Low training set size</strong>: causes $J_{train}(\Theta)$ to be low and $J_{CV}(\Theta)$ to be high.</p><p><strong>Large training set size</strong>: causes both $J_{train}(\Theta)$ and $J_{CV}(\Theta)$ to be high with $J_{train}(\Theta)$≈$J_{CV}(\Theta)$.</p><p>If a learning algorithm is suffering from <strong>high bias</strong>, getting more training data will not <strong>(by itself)</strong> help much.</p><p><img src="figure7.png" alt=""></p><p><strong>Experiencing high variance:</strong></p><p><strong>Low training set size</strong>: $J_{train}(\Theta)$ will be low and $J_{CV}(\Theta)$ will be high.</p><p><strong>Large training set size</strong>: $J_{train}(\Theta)$ increases with training set size and $J_{CV}(\Theta)$ continues to decrease without leveling off. Also, $J_{train}(\Theta)$ &lt; $J_{CV}(\Theta)$ but the difference between them remains significant.</p><p>If a learning algorithm is suffering from <strong>high variance</strong>, getting more training data is likely to help.</p><p><img src="figure8.png" alt=""></p><hr><p>当出现欠拟合时，增大数据量是没有用处的；而在过拟合时，增大数据量可以使得训练集数据与真实数据更加接近，使得模型的精度提高</p></li><li><p>Our decision process can be broken down as follows:</p><ul><li><p><strong>Getting more training examples:</strong> Fixes high variance</p></li><li><p><strong>Trying smaller sets of features:</strong> Fixes high variance</p></li><li><p><strong>Adding features:</strong> Fixes high bias</p></li><li><p><strong>Adding polynomial features:</strong> Fixes high bias</p></li><li><p><strong>Decreasing λ:</strong> Fixes high bias</p></li><li><p><strong>Increasing λ:</strong> Fixes high variance.</p></li></ul></li><li><p>The recommended approach to solving machine learning problems is to:</p><ul><li>Start with a simple algorithm, implement it quickly, and test it early on your cross validation data.</li><li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li><li>Manually examine the errors on examples in the cross validation set and try to spot a trend where most of the errors were made.</li></ul></li></ol><h1 id="第七周"><a href="#第七周" class="headerlink" title="第七周"></a>第七周</h1><ol><li><p>The form of SVM model’s cost function is similiar to the cost function of logistic regression<br>$$<br>\displaystyle minC\sum_{i=1}^{m}[y^{(i)}cost_1(\theta^Tx^{(i)}) + (1 - y^{(i)})cost_0(\theta^Tx^{(i)})] + \frac{1}{2}\sum_{i = 1} ^n \theta^2_j<br>$$<br>and the two parts of the $cost$ are some function which have the following properties<br>$$<br>\begin{cases}\theta^Tx \ge 1 &amp; y = 1 \\ \theta^Tx\le -1 &amp; y = 0\end{cases}<br>$$</p></li><li><p>support vector machine is also called large margin machine</p></li><li><p>the value of $C$ denotes the value we view to the loss of training data</p><p>if $C$ is very large, then even if there are some bad data exist in the training data, the algorithm will still try to set the margin according to the training data. =&gt; high variance</p><p>if $C$ is reasonably small, then the algorithm could ignore the bad data and try to get a subjective regression =&gt; high bias</p></li><li><p>SVM with kernels<br>$$<br>\displaystyle minC\sum_{i=1}^{m}[y^{(i)}cost_1(\theta^Tf^{(i)}) + (1 - y^{(i)})cost_0(\theta^Tf^{(i)})] + \frac{1}{2}\sum_{i = 1} ^n \theta^2_j<br>$$</p></li><li><p>$\sigma^2$ ‘s influence on model</p><p>if it is large, then it will have very blury decision which results in high bias</p><p>if it is small, it will have somewhat very critical criticism which results in high variance</p></li><li><p>if $n$ is much large than $m$, then it is better to use logistic regress or SVM without a kernel</p><p>if $n$ is small and $m$ is intermediate(about ten times at maximum), then it is better to use SVM with Gaussian kernel</p><p>if $n$ is small and $m$ is large, add more features and then use logistic regression or SVM without kernel</p></li></ol><h1 id="第八周"><a href="#第八周" class="headerlink" title="第八周"></a>第八周</h1><h2 id="K-means-algoirithm"><a href="#K-means-algoirithm" class="headerlink" title="K-means algoirithm"></a>K-means algoirithm</h2><ol><li><p>unsupervised learning algorithm is some model given unlabeled data and get to find the structure of data. There are many unsupervised learning algorithm and one of them is <code>clustering</code></p></li><li><p>A famous clustering algorithm - K-means algorithm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Randomly initializa K cluster centroids </span><br><span class="line">Repeat &#123;</span><br><span class="line">for i = 1 to m</span><br><span class="line">assign the index of cluster centroid to every point</span><br><span class="line"></span><br><span class="line">for k = 1 to K</span><br><span class="line">update the new position of the cluster centroid</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>the optimization objective of K-means algorithm  $\displaystyle \frac{1}{m} \sum_{i = 1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2$, where $x^{(i)}$ is the position of i-th data and $\mu_{c^{(i)}}$ is the cluster centroid which the i-th data is assigned. In this case, the cost function will never increase during the process of algorithm. </p><p>why do we care about that?</p><ul><li>it will help to debug</li><li>we can use this to make K-means better</li></ul></li><li><p>how to randomly initialize K cluster centroids to avoid the local optima</p><ul><li>randomly pick K training examples</li><li>set the cluster centroids to these K examples</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to 100(range from 50 to 1000)</span><br><span class="line">randomly initialize K-means # better if K range from 2 - 10</span><br><span class="line">run K-means</span><br><span class="line">compute cost function</span><br><span class="line"></span><br><span class="line">pick clustering that gave the lowest cost</span><br></pre></td></tr></table></figure></li><li><p>what is the right value of K?</p><p><img src="figure9.png" alt=""></p></li></ol><h2 id="Data-demensionality-reduction"><a href="#Data-demensionality-reduction" class="headerlink" title="Data demensionality reduction"></a>Data demensionality reduction</h2><ol><li><p>data compression</p><p>if some features corrlate to each other, then maybe we can represent then by some curve</p><p>After that, we will replace them with this only one feature which will reduce the demensionality</p></li><li><p>data visualization</p><p>reduce the demensionality to 2D or 3D to print out the graph of data to look for some features </p></li><li><p>PCA(principal component analysis) is trying to find a lower dimensional surface onto which to project the data from $n$-dimensions to $k$-dimensions</p><ul><li>data preprocessing (feature scaling / mean normalization)</li><li>compute “covariance matrix” $ \sum = \displaystyle\frac{1}{m}\sum_{i = 1}^n(x^{(i)})(x^{(i)})^T$</li><li>compute “eigenvectors” of matrix $\sum$ by “Singular Value Decomposition”</li><li>get the compressed data by parameters from last step</li></ul></li><li><p>recounstuction from compressed representation<br>$$<br>z = U_{\text{reduce}}^T x   &lt;=&gt; x \approx U_{\text{reduce}}z<br>$$</p></li><li><p>how to choose the right number of $K$</p><p>recall that the cost function of PCA is $\displaystyle \frac{1}{m}\sum_{i = 1}^m ||x^{(i)} - x_{\text{approx}}^{(i)}||^2$, and total variation in data is $\displaystyle \frac{1}{m}\sum_{i = 1}^m ||x^{(i)}||^2$. typically, choose $k$ to be smallest value so that $\frac{\displaystyle \frac{1}{m}\sum_{i = 1}^m ||x^{(i)} - x_{\text{approx}}^{(i)}||^2}{\displaystyle \frac{1}{m}\sum_{i = 1}^m ||x^{(i)} ||^2} \le 1\% $.</p><p>Guess what, it can be calculated by the parameters “S” returned by SVD function, which is a diagonal matrix. And the formula is $\displaystyle 1 - \frac{\sum^k_i s_{ii}}{\sum_i^{n}s_{ii}} \le 1\% $</p></li><li><p>when using PCA on dataset, we should get parameters from SVD only from training set and apply it to cross validation set and test set. </p></li><li><p>bad use of PCA: to prevent overfitting because there would be less features after applying PCA. This might work OK, but isn’t a good way to address overfitting. Use regularization instead. </p><p>The reason of that is PCA would throw some information which may be valuable.</p></li><li><p>PCA is sometimes used where it shouldn’t be. Think about doing the whole thing without using PCA? </p><p>Before implementing PCA, first try running whatever you want to do with the original/raw data $x^{(i)}$. Only if that doesn’t do what you want, then implement PCA and consider using $z^{(i)}$</p></li></ol><h2 id="about-assignment"><a href="#about-assignment" class="headerlink" title="about assignment"></a>about assignment</h2><ol><li>$||xx||^2$ 表示的是二范数，也就是一个平方根</li><li>在对矩阵操作的时候，</li></ol><h1 id="第九周"><a href="#第九周" class="headerlink" title="第九周"></a>第九周</h1><h2 id="anomaly-detect-algorithm"><a href="#anomaly-detect-algorithm" class="headerlink" title="anomaly detect algorithm"></a>anomaly detect algorithm</h2><ol><li><p>assume that every features of data follow Gaussian distribution, and we are going to get the parameter of all these Gaussian distribution</p><ul><li>choose features $x_i$ that you think might be indicative of anomalous examples.</li><li>fit parameters $\mu_1, \mu_2, …, \mu_n$ , $\sigma_1^2, …, \sigma_n^2$</li><li>given new example $x$, compute $p(x) = \prod_{j = 1} ^np(x_j; \mu_j;\sigma_j^2)$, anomaly if $p(x) &lt; \epsilon$</li></ul></li><li><p>suppose our model gives high accuracy when evaluating on the cross validation set or test set, maybe it still doesn’t have a good performance because of skewed classes</p></li><li><p>why not supervised learning algorithm?</p><p>| Anomaly detection                                            | Supervised learning                                          |<br>| :———————————————————– | :———————————————————– |<br>| very small number of positve examples; <br>large number of negative examples | large number of positive and negative example                |<br>| Many different “types” of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like;<br>future anomalies may look nothing like any of the anomalous examples we’ve seen so far. | Enough positive examples for algorithm to get a sense of what positive examples are like, future positive examples likely to be similar to ones in training set. |<br>| fraud detection; <br>Manufacturing(e.g. aircraft engines)<br>monitoring machines in a data center | email spam classification<br>weather prediction<br>cancer classification |</p></li><li><p>choose what features to use</p><p>if a certain feature doesn’t look like gaussian distribution, then maybe it is better to get a log, or get some power root</p></li></ol><h2 id="content-based-recommender-system"><a href="#content-based-recommender-system" class="headerlink" title="content-based recommender system"></a>content-based recommender system</h2><ol><li><p>give some features to the content of the  movie and score them</p><p>for each user, learn a parameter. Predict user as rating movie with the parameter</p></li><li><p>the cost function of this algorithm is just like linear regression</p></li><li><p>given $x^{(1)},x^{(2)}, x^{(3)}… $, can estimate $\theta^{(1)},\theta^{(2)}, \theta^{(3)}… $</p></li></ol><h2 id="Collaborative-Filter"><a href="#Collaborative-Filter" class="headerlink" title="Collaborative Filter"></a>Collaborative Filter</h2><ol><li>the algorithm could learn what features to use</li><li>given the parameter from user as same as the “content-based recommender system”, try to score the features of moive. The cost function has the same form of the linear regression</li><li>given $\theta^{(1)},\theta^{(2)}, \theta^{(3)}… $, can estimate $x^{(1)},x^{(2)}, x^{(3)}… $</li></ol><hr><p>the traditional way to compund these two algorithm is to first guess some parameter of the user favor, then use “collaborative filter” to get the features of movie, then “content-based recommender system” to get a more accurate parameter of user, and repeat on</p><h2 id="Collaborative-Filtering-algorithm"><a href="#Collaborative-Filtering-algorithm" class="headerlink" title="Collaborative Filtering algorithm"></a>Collaborative Filtering algorithm</h2><ol><li>if we mix these two algorithm together by put two cost function into one, then we can get a new algorithm wihich could simultaneously update the parameters of user and the features of movie</li><li><p>the process of “collaborative filtering algorithm”</p><ul><li>initialize parameter of user and features of movie</li><li>minimize using gradient descent</li><li>get the prediction of user for some movie by the parameter learned before</li></ul></li><li><p>it is also called “low rank matrix factorization”</p></li><li><p>how to find movies that user might favor? Try to find some data that has little difference compared to the movie user like.</p></li><li><p>what if a new user join in and hasn’t seen any movies? “Mean Normalization”  could fix that.</p><p><img src="figure10.png" alt=""></p></li></ol><h1 id="第十周"><a href="#第十周" class="headerlink" title="第十周"></a>第十周</h1><h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><h3 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h3><ol><li>the normal algorithm</li><li>plot $J_{\text{train}}(\theta)$ as a function of the number of iterations of gradient descent to see if it is performing well, then we can tune the learning rate or so</li></ol><h3 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h3><ol><li><p>In this case, the cost funciton shouldn’t include the $m$ parameters because the batch we use doesn’t have the scale of $m$. So now the cost function is $cost(\theta, (x^{(i)}, y^{(i)})) = \frac{1}{2}(h_\theta(x^{(i)}) - y^{(i)})^2$.</p><p>But as for the loss of training set, it still should use the $m$ term.</p></li><li><p>in every iteration, just use one example to update the $\theta$ parameters</p></li><li><p>stochastic gradient descent doesn’t just converge to teh global minimum, it will oscillate a bit around the global minimum.</p></li><li><p>as for this algorithm, we need to plot something different to get a tuition about how it is performing.</p><ul><li>during leartning, compute $cost(\theta, (x^{(i)}, y^{(i)}))$ before updating $\theta$ using $(x^{(i)}, y^{(i)})$. </li><li>every 1000 iterations(say), plot $cost(\theta, (x^{(i)}, y^{(i)}))$ averaged over the last 1000 examples processed by algorithm.</li></ul></li><li><p>sometimes it is better to set this number of iterations small, because we can get more detail about the performing of algorithm; However, sometimes it is better to use a large number because maybe in detail there is just noise everywhere, and the large iteraitons could get us a global plot in this case. </p></li><li><p>it is better to set the learning rate to decrease by time because eventually the algorithm will oscillate around the optima value. As Andrew suggest, maybe it is good to use something like $\alpha= \displaystyle \frac{const1}{iterations + const2}$</p></li></ol><h3 id="Mini-batch-gradient-descent"><a href="#Mini-batch-gradient-descent" class="headerlink" title="Mini-batch gradient descent"></a>Mini-batch gradient descent</h3><ol><li><p>every batch is a subset of training data set with the size we set, and we are going to update $\theta$ parameters based on these mini-batches</p></li><li><p>why look for a min batch rather than a single case of training examples?</p><p>In this case, we can get a better and efficient gradient descent algorithm, because we can parallelize the calculation by vectorization.</p></li></ol><h2 id="Online-Learning-set"><a href="#Online-Learning-set" class="headerlink" title="Online Learning set"></a>Online Learning set</h2><p>update the parameter of website or a specific user based on the data generated by them</p><h2 id="Map-reduce-and-Dara-Parallelism"><a href="#Map-reduce-and-Dara-Parallelism" class="headerlink" title="Map-reduce and Dara Parallelism"></a>Map-reduce and Dara Parallelism</h2><p>many machines doing the same task separately, and the work these machines doing all together makes up the origin sing task which maybe impossible to complete in one single machine.</p><h1 id="第十一周"><a href="#第十一周" class="headerlink" title="第十一周"></a>第十一周</h1><h2 id="Photo-OCR-pupeline"><a href="#Photo-OCR-pupeline" class="headerlink" title="Photo OCR pupeline"></a>Photo OCR pupeline</h2><ol><li>the basic process of OCR<ul><li>text detection </li><li>character segmentation</li><li>character classification</li></ul></li><li>sliding windows algirithm for looking for pedestrians<ul><li>slide a littel window with a fixed size to go over the all image </li><li>make the window bigger and slide it all over the image, but then transform this bigger window into the fixed size just like before</li></ul></li></ol><h2 id="Artificial-Data-Synthesis"><a href="#Artificial-Data-Synthesis" class="headerlink" title="Artificial Data Synthesis"></a>Artificial Data Synthesis</h2><ol><li><p>as for the example of character recognition, we can use font libraries form the internet</p><p>and we can introduce distortion to the origin image </p></li><li><p>as for speech recognition, </p><ul><li>introduce a distortion such as cellphone connection, </li><li>noisy background: crowd, vehicle, machinery</li></ul></li><li><p>discussion on getting more data</p><ul><li>make sure you have a low bias classifier before expending the effort.</li><li>“How much work would it be to get 10 times as much data as we currently have?”<ul><li>artificial data synthesis</li><li>collect/label it ourselves</li><li>“Crowd source”</li></ul></li></ul></li></ol><h2 id="Ceiliing-Analysis"><a href="#Ceiliing-Analysis" class="headerlink" title="Ceiliing Analysis"></a>Ceiliing Analysis</h2><p>what part of the pipeline to work on next?</p><p>assume we are part of the component of algorithm, then go from the source of data flow and get the part of job perfect, look for the final performance of algorithm. If it exert a great influence on final result, then it is worth to get more work on this part of pipeline. Then we go on to the next part while keep the previous perfect part, keep trying to see which part is more worth the studying.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文用于记录学习Coursera中Machine Learning课程的笔记&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://notes-hongbo.top/categories/Machine-Learning/"/>
    
    
      <category term="AI" scheme="http://notes-hongbo.top/tags/AI/"/>
    
      <category term="Coursera" scheme="http://notes-hongbo.top/tags/Coursera/"/>
    
  </entry>
  
</feed>
